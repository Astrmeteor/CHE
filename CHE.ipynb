{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5342bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/xie/NN/CHE', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/xie/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/local/lib/python3.8/dist-packages/pyknp-0.4.5-py3.8.egg', '/usr/lib/python3/dist-packages', '/home/xie/.local/lib/python3.8/site-packages/IPython/extensions', '/home/xie/.ipython', '/home/xie/NN/CHE', '/home/xie/NN/CHE', '../CHE', '../CHE', '/home/xie/NN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/xie/NN\")\n",
    "import math \n",
    "import pathos\n",
    "from itertools import product\n",
    "from seal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d48c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change(weight, parms):\n",
    "    \"\"\"\n",
    "    :param weight: weight of conv layer\n",
    "    :param parms: encryption parameter dictionary\n",
    "    :return: changed weight\n",
    "    \"\"\"\n",
    "    weight = weight.numpy()\n",
    "    weight_temp = np.zeros(weight.shape).tolist()\n",
    "    for outer, inner, i in product(range(weight.shape[0]), range(weight.shape[1]), range(weight.shape[2])):\n",
    "        weight_temp[outer][inner][i] = parms['encoder'].encode(weight[outer][inner][i].item(), parms['scale'])\n",
    "    return weight_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c4295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_change(bias, parms):\n",
    "    \"\"\"\n",
    "    :param bias: bias of conv layer\n",
    "    :param parms: encryption parameter dictionary\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for i in range(bias.__len__()):\n",
    "        bias[i] = parms['encoder'].encode(bias[i], parms['scale'])\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf6e1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients(mu, sigma, gamma, beta, eps, name):\n",
    "    \"\"\"\n",
    "    :param mu: BN mu\n",
    "    :param sigma: BN sigma\n",
    "    :param gamma: BN gamma\n",
    "    :param beta: BN beta\n",
    "    :param eps: BN eps\n",
    "    :param name: BN paradigm, CBA or CAB\n",
    "    :return: coefficients merging\n",
    "    \"\"\"\n",
    "    if name == 'CBA':\n",
    "        temp = gamma / np.sqrt(sigma + eps)\n",
    "        a = np.power(temp, 2)\n",
    "        b = 2 * (beta - temp * mu) * temp\n",
    "        c = np.power((beta - temp * mu), 2)\n",
    "    elif name == 'CAB':\n",
    "        a = gamma / np.sqrt(sigma + eps)\n",
    "        b = 0\n",
    "        c = beta - a * mu\n",
    "    return a, b / a, c / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e40e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_diag(weight):\n",
    "    \"\"\"\n",
    "    :param weight: weight of FC layer\n",
    "    :return: padded and diagonalization weight of FC layer\n",
    "    \"\"\"\n",
    "    weight = np.array(weight)\n",
    "    weight = np.pad(weight, pad_width=((0, 0), (0, weight.shape[0] - weight.shape[1])))\n",
    "    W = []\n",
    "    for i in range(weight.shape[0]):\n",
    "        if i == 0:\n",
    "            W.append(np.diag(weight, i).tolist())\n",
    "        else:\n",
    "            W.append(np.concatenate([np.diag(weight, -i), np.diag(weight, weight.shape[0] - i)]).tolist())\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494e7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rotation(m, f):\n",
    "    \"\"\"\n",
    "    :param m: input size\n",
    "    :param f: filter size\n",
    "    :param p: padding number\n",
    "    :return: rotation index\n",
    "    \"\"\"\n",
    "    idx = []\n",
    "    for i in range(f):\n",
    "        start = i * m\n",
    "        for j in range(f):\n",
    "            if i == f - 1 & j == f - 1:\n",
    "                continue\n",
    "            a = start + j\n",
    "            if j == f - 1:\n",
    "                a = (i + 1) * m - 1\n",
    "                idx.append(a + 1)\n",
    "            else:\n",
    "                idx.append(a + 1)\n",
    "    assert len(idx) == pow(f, 2) - 1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a789b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_conv(conv_weight, conv_bias, inputs, f, mask, parms):\n",
    "    \"\"\"\n",
    "    multiprocessing\n",
    "    :param conv_weight: weight of each output channel\n",
    "    :param conv_bias: bias of each output channel\n",
    "    :param inputs: input feature maps (fixed)\n",
    "    :param f: filter size (fixed)\n",
    "    :param mask: mask (fixed)\n",
    "    :param parms: encryption parameters (fixed)\n",
    "    :return: result of each output channel\n",
    "    \"\"\"\n",
    "    # compute element-wise and accumulation\n",
    "    in_channel = conv_weight[0].__len__()\n",
    "    Z = []\n",
    "    for inner in range(in_channel):\n",
    "        Y = []\n",
    "        for i in range(f * f):\n",
    "            parms['evaluator'].mod_switch_to_inplace(conv_weight[inner][i], inputs[inner][i].parms_id())\n",
    "            Y.append(parms['evaluator'].multiply_plain(inputs[inner][i], conv_weight[inner][i]))\n",
    "            Z.append(parms['evaluator'].add_many(Y))\n",
    "    Z = parms['evaluator'].add_many(Z)\n",
    "    parms['evaluator'].rescale_to_next_inplace(Z)\n",
    "\n",
    "    # add bias\n",
    "    parms['evaluator'].mod_switch_to_inplace(conv_bias, Z.parms_id())\n",
    "    Z.scale(2 ** int(math.log2(conv_bias.scale())))\n",
    "    parms['evaluator'].add_plain_inplace(Z, conv_bias)\n",
    "    mask_encode = mask\n",
    "    parms['evaluator'].mod_switch_to_inplace(mask_encode, Z.parms_id())\n",
    "    parms['evaluator'].multiply_plain_inplace(Z, mask_encode)\n",
    "    parms['evaluator'].rescale_to_next_inplace(Z)\n",
    "    \n",
    "    print(\"hello world\")\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "def convolution(input, conv_weight, conv_bias, s, parms):\n",
    "\n",
    "    out_channels = []\n",
    "    in_channel = conv_weight[0].__len__()\n",
    "    out_channel = conv_weight.__len__()\n",
    "    f = int(math.sqrt(conv_weight[0][0].__len__()))\n",
    "    p = 0\n",
    "    parms['n'] = int((parms['m'] + 2 * p - f) / s + 1)\n",
    "    y = parms[\"context\"].key_context_data().parms()\n",
    "    \n",
    "    # search rotation index\n",
    "    idx = count_rotation(parms['m'], f)\n",
    "    for i in range(idx.__len__()):\n",
    "        idx[i] = parms[\"valid_vector\"][idx[i]]\n",
    "\n",
    "    # valid values\n",
    "    valid_index = []\n",
    "    mask = [0 for i in range(parms['slots'])]\n",
    "    for i in range(parms['n']):\n",
    "        for j in range(parms['n']):\n",
    "            valid_index.append(i * s * parms['m'] + j * s)\n",
    "            mask[parms[\"valid_vector\"][i * s * parms['m'] + j * s]] = 1\n",
    "    mask = parms['encoder'].encode(mask, parms['scale'])\n",
    "    mask.set_parms(y)\n",
    "    inputs = [[0 for i in range(f * f)] for j in range(in_channel)]\n",
    "\n",
    "    for i in range(in_channel):\n",
    "        inputs[i][0] = input[i]\n",
    "        inputs[i][0].set_parms(y)\n",
    "        for j in range(f * f):\n",
    "            inputs[i][j] = parms['evaluator'].rotate_vector(input[i], idx[j - 1], parms['galois_keys'])\n",
    "            inputs[i][j].set_parms(y)\n",
    "    \n",
    "    print(\"Parallel-conv start\")\n",
    "    pool = pathos.multiprocessing.ProcessPool()\n",
    "    inputs_s = [inputs] * out_channel\n",
    "    f_s = [f] * out_channel\n",
    "    mask_s = [mask] * out_channel\n",
    "    parms_s = [parms] * out_channel\n",
    "    \n",
    "\n",
    "    result = pool.amap(multi_conv, (conv_weight, conv_bias, inputs_s, f_s, mask_s, parms_s)).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # out_channels = result\n",
    "\n",
    "    # set output of layer as input of next layer\n",
    "    parms['m'] = parms['n']\n",
    "    # set invalid vector\n",
    "    Z = []\n",
    "    for i in valid_index:\n",
    "        Z.append(parms[\"valid_vector\"][i])\n",
    "    parms[\"valid_vector\"] = Z\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "503968ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_act(x, b, c, parms):\n",
    "    channels = len(x)\n",
    "    X = []\n",
    "    for i in range(channels):\n",
    "        # HE square\n",
    "        # x^2\n",
    "        x_2 = parms['evaluator'].square(x[i])\n",
    "        parms['evaluator'].relinearize_inplace(x_2, parms['relin_keys'])\n",
    "        parms['evaluator'].rescale_to_next_inplace(x_2)\n",
    "\n",
    "        # b * x\n",
    "        b_prime = parms['encoder'].encode(b[i].item(), parms['scale'])\n",
    "        parms['evaluator'].mod_switch_to_inplace(b_prime, x[i].parms_id())\n",
    "        b_x = parms['evaluator'].multiply_plain(x[i], b_prime)\n",
    "        parms['evaluator'].rescale_to_next_inplace(b_x)\n",
    "\n",
    "        c_prime = parms['encoder'].encode(c[i].item(), parms['scale'])\n",
    "\n",
    "        parms['evaluator'].mod_switch_to_inplace(c_prime, x_2.parms_id())\n",
    "        parms['evaluator'].mod_switch_to_inplace(b_x, x_2.parms_id())\n",
    "\n",
    "        x_2.scale(2 ** int(math.log2(c_prime.scale())))\n",
    "        b_x.scale(2 ** int(math.log2(c_prime.scale())))\n",
    "\n",
    "        X.append(parms['evaluator'].add_plain(parms['evaluator'].add(x_2, b_x), c_prime))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_pack(x, pamrs):\n",
    "    # HE rotation\n",
    "    # idx: valuable idx; rot_idx: rotation index\n",
    "    idx = parms[\"valid_vector\"]\n",
    "    # generate all-zeroes mask\n",
    "    mask = [0 for h in range(parms['slots'])]\n",
    "    mask[0] = 1\n",
    "    mask = parms['encoder'].encode(mask, parms['scale'])\n",
    "    parms['evaluator'].mod_switch_to_inplace(mask, x.parms_id())\n",
    "    Z = []\n",
    "    Z.append(parms['evaluator'].multiply_plain(x, mask))\n",
    "    for k in range(self.parms['n'] * parms['n'] - 1):\n",
    "        # HE element-wise multiplication and addition\n",
    "        mask = [0 for h in range(parms['slots'])]\n",
    "        mask[idx[k + 1]] = 1\n",
    "        mask = parms['encoder'].encode(mask, parms['scale'])\n",
    "        parms['evaluator'].mod_switch_to_inplace(mask, x.parms_id())\n",
    "        Z.append(\n",
    "            parms['evaluator'].rotate_vector(\n",
    "                parms['evaluator'].multiply_plain(x, mask),\n",
    "            rot_idx[k], parms['galois_keys']\n",
    "            )\n",
    "        )\n",
    "    x = parms['evaluator'].add_many(Z)\n",
    "        \n",
    "    return parms['evaluator'].rotate_vector(x, -(n * n * i), parms['galois_keys'])\n",
    "\n",
    "\n",
    "def pack_vectors(x, n, parms):\n",
    "    channels = x.__len__()\n",
    "    Z = []\n",
    "    # Y.append(x[0])\n",
    "    rot_idx = []\n",
    "    for j in range(1, n * n):\n",
    "        rot_idx.append(parms[\"valid_vector\"][j] - j)\n",
    "    y = parms[\"context\"].key_context_data().parms()\n",
    "    for i in range(channels):\n",
    "        x[i].set_parms(y)\n",
    "    pool = pathos.multiprocessing.ProcessPool()\n",
    "    parms_s = [parms] * channels\n",
    "    \n",
    "    result = pool.amap(multi_pack, (x, parms_s)).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    Z = parms['evaluator'].add_many(result)\n",
    "    parms['evaluator'].rescale_to_next_inplace(Z)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(self, x, weight, bias):\n",
    "    Y = []\n",
    "    temp = x\n",
    "\n",
    "    rot_single = weight.__len__() - bias.__len__() + 1\n",
    "\n",
    "    for i in range(weight.__len__()):\n",
    "\n",
    "        w = parms['encoder'].encode(weight[i], parms['scale'])\n",
    "        parms['evaluator'].mod_switch_to_inplace(w, x.parms_id())\n",
    "        Y.append(\n",
    "            parms['evaluator'].multiply_plain(temp, w)\n",
    "        )\n",
    "        if i != 0 and i < rot_single:\n",
    "            temp = parms['evaluator'].rotate_vector(x, i + 1, parms['galois_keys'])\n",
    "\n",
    "        B = []\n",
    "        if i != weight.__len__() - 1 and i >= rot_single:\n",
    "            B.append(parms['evaluator'].rotate_vector(x, i + 1, self.parms['galois_keys']))\n",
    "            B.append(parms['evaluator'].rotate_vector(x, -weight.__len__() + i + 1, parms['galois_keys']))\n",
    "            temp = parms['evaluator'].add_many(B)\n",
    "    Y = parms['evaluator'].add_many(Y)\n",
    "    parms['evaluator'].rescale_to_next_inplace(Y)\n",
    "\n",
    "    B = parms['encoder'].encode(bias, parms['scale'])\n",
    "\n",
    "    parms['evaluator'].mod_switch_to_inplace(B, Y.parms_id())\n",
    "    Y.scale(2 ** int(math.log2(B.scale())))\n",
    "    return parms['evaluator'].add_plain(Y, B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
